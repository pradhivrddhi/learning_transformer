{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.config import FetchFromPretrained as ConfigFromPretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.tokenizer import FetchFromPretrained as TokenizerFromPretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 741\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset('AlekseyKorshuk/books')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'google-bert/bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.39.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigFromPretrained(model_ckpt=model_ckpt).fetch()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.hidden_size = 1024\n",
    "config.intermediate_size = 64\n",
    "config.compress_layer_size = 64\n",
    "config.max_position_embeddings = 128\n",
    "config.num_attention_heads = 8\n",
    "config.num_hidden_layers = 8\n",
    "config.device = device\n",
    "config.dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TokenizerFromPretrained(model_ckpt=model_ckpt).fetch()\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_count = len(data['train'])\n",
    "files_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 666)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index_1, split_index_2 = int(files_count * 0.8), int(files_count * 0.9)\n",
    "split_index_1, split_index_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_random_files(split):\n",
    "    indices = []\n",
    "    if split == 'train':\n",
    "        file_id = random.randint(0, split_index_1)\n",
    "    elif split == 'test':\n",
    "        file_id = random.randint(split_index_1, split_index_2)\n",
    "    elif split == 'val':\n",
    "        file_id = random.randint(split_index_2, files_count)\n",
    "\n",
    "    file = data['train'][file_id]['text']\n",
    "\n",
    "    input_ids = tokenizer(file, return_tensors='pt', add_special_tokens=False).input_ids[0]\n",
    "    if len(input_ids) < config.max_position_embeddings + 2*batch_size:\n",
    "        return get_data_from_random_files(split)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    input_ids = get_data_from_random_files(split=split)\n",
    "    ix = torch.randint(len(input_ids) - config.max_position_embeddings, (batch_size,))\n",
    "    x = torch.stack([input_ids[i:i + config.max_position_embeddings] for i in ix])\n",
    "    y = torch.stack([input_ids[i + 1:i + config.max_position_embeddings + 1] for i in ix])\n",
    "    x, y = x.to(torch.int64).to(device), y.to(torch.int64).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1524018 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1045, 2156, 2054,  ..., 1996, 3409, 1012])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_from_random_files('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5138,  2256, 15961,  ...,  2068,  1012,  1996],\n",
       "         [ 4932,  2077,  2002,  ..., 12707,  1059, 29602],\n",
       "         [ 2172,  1010,  2339,  ...,  2057,  2089,  2196],\n",
       "         ...,\n",
       "         [ 9496,  5267,  1997,  ..., 20682,  2008, 25407],\n",
       "         [ 4452,  2025,  1012,  ...,  2492,  2000,  2108],\n",
       "         [13550,  1999,  2026,  ...,  2151,  2204, 18971]], device='cuda:0'),\n",
       " tensor([[ 2256, 15961,  1012,  ...,  1012,  1996, 12168],\n",
       "         [ 2077,  2002,  2018,  ...,  1059, 29602,  2140],\n",
       "         [ 1010,  2339,  2123,  ...,  2089,  2196,  2113],\n",
       "         ...,\n",
       "         [ 5267,  1997,  2335,  ...,  2008, 25407,  2068],\n",
       "         [ 2025,  1012,  1046,  ...,  2000,  2108,  7463],\n",
       "         [ 1999,  2026,  4540,  ...,  2204, 18971,  2000]], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.head.text_generator_decoder_only import TextGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TextGenerator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iter_ticks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.7339e-01, -1.3702e-01,  5.3929e-01,  ..., -2.3304e-01,\n",
       "            2.0232e-01, -6.9563e-01],\n",
       "          [ 6.3313e-01,  3.0445e-01, -1.2546e+00,  ...,  5.2929e-01,\n",
       "            4.2256e-01,  1.9288e-01],\n",
       "          [ 7.4196e-02, -3.1074e-01,  4.6293e-02,  ...,  4.9908e-02,\n",
       "            4.1873e-01,  6.5812e-01],\n",
       "          ...,\n",
       "          [-8.5314e-01,  1.7837e-01, -4.8513e-01,  ..., -3.3449e-02,\n",
       "            6.3130e-01, -2.2827e-01],\n",
       "          [ 4.8797e-02, -2.2342e-02,  9.1830e-01,  ..., -3.7052e-02,\n",
       "            1.9870e-01, -1.0240e+00],\n",
       "          [-6.6562e-01, -5.8883e-01, -1.1472e+00,  ...,  1.7549e-02,\n",
       "           -8.2376e-02,  1.9792e-01]],\n",
       " \n",
       "         [[-1.4724e-01, -9.3736e-01, -1.2256e-02,  ..., -9.7147e-01,\n",
       "            1.4565e-01, -4.7422e-01],\n",
       "          [ 6.9703e-01,  7.7893e-02, -4.2811e-01,  ...,  1.0970e+00,\n",
       "            2.9015e-01, -3.1483e-01],\n",
       "          [-9.2293e-01,  5.8921e-01, -2.9144e-01,  ...,  7.0853e-01,\n",
       "            1.8725e-01,  1.0020e+00],\n",
       "          ...,\n",
       "          [-2.4326e-01,  2.5162e-01, -3.6778e-01,  ..., -2.3791e-01,\n",
       "           -1.1236e-01, -7.0145e-02],\n",
       "          [-6.8291e-01,  1.9760e-01,  8.5174e-01,  ...,  4.6788e-01,\n",
       "            1.9535e-01, -5.2035e-01],\n",
       "          [-1.1150e+00,  5.3172e-01, -6.4360e-01,  ...,  3.2687e-01,\n",
       "           -1.0458e-01, -2.2968e-01]],\n",
       " \n",
       "         [[-4.2328e-01, -9.3198e-01, -3.0551e-02,  ..., -1.7198e-01,\n",
       "           -2.9710e-01, -7.8276e-01],\n",
       "          [ 6.9137e-01, -7.6988e-01, -3.8461e-01,  ..., -8.3158e-03,\n",
       "           -3.4737e-01, -3.6265e-02],\n",
       "          [ 3.2943e-01,  2.6167e-04, -3.1254e-01,  ...,  2.5883e-01,\n",
       "            1.0484e+00,  6.7836e-01],\n",
       "          ...,\n",
       "          [-5.1144e-01, -5.0504e-01,  1.0364e-01,  ..., -1.2428e-01,\n",
       "            6.7159e-01,  3.8128e-01],\n",
       "          [-1.2407e-01,  4.8459e-02,  7.0271e-01,  ...,  2.7422e-02,\n",
       "            3.2031e-01, -9.2650e-01],\n",
       "          [-1.3059e+00,  1.0166e-01,  8.5072e-02,  ...,  5.7644e-01,\n",
       "           -5.0897e-01, -2.1515e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-5.1210e-02, -1.2004e+00,  1.4738e+00,  ..., -1.4545e+00,\n",
       "            4.0156e-01, -4.4295e-01],\n",
       "          [ 3.2979e-01,  1.1111e-01,  1.0129e-01,  ..., -2.5760e-01,\n",
       "            3.3644e-01,  8.0901e-02],\n",
       "          [-4.2478e-01,  3.1085e-01, -3.3305e-02,  ..., -7.1584e-02,\n",
       "            2.5354e-01, -1.3999e-01],\n",
       "          ...,\n",
       "          [-3.8899e-01, -7.0352e-01,  2.7345e-01,  ...,  7.2256e-02,\n",
       "           -1.8506e-01, -1.6262e-01],\n",
       "          [-1.7610e-01,  2.6197e-01,  3.2221e-01,  ..., -1.9510e-01,\n",
       "            3.0130e-01, -1.6908e-01],\n",
       "          [-3.2268e-01, -2.2786e-01, -5.5560e-01,  ...,  2.8972e-01,\n",
       "           -2.8925e-01, -3.0365e-01]],\n",
       " \n",
       "         [[-8.4236e-01, -3.3629e-02,  3.4706e-01,  ..., -9.5488e-01,\n",
       "            1.6460e-01,  3.8990e-01],\n",
       "          [ 4.8445e-01, -2.0324e-01, -1.5979e-01,  ..., -3.2120e-01,\n",
       "            4.5540e-01,  6.7094e-01],\n",
       "          [-3.3831e-01,  7.6064e-01, -2.1323e-01,  ...,  9.3744e-01,\n",
       "           -1.5938e-01,  1.2336e+00],\n",
       "          ...,\n",
       "          [-7.9271e-01, -8.1274e-01, -1.4152e-01,  ..., -3.8752e-01,\n",
       "            7.3226e-01,  4.4096e-01],\n",
       "          [-2.6333e-01, -1.1631e-01,  5.6502e-01,  ..., -1.2868e-01,\n",
       "            4.2675e-01, -7.8140e-01],\n",
       "          [-4.2420e-01, -7.8728e-02,  6.2711e-01,  ..., -3.4662e-01,\n",
       "            2.4253e-01,  3.1987e-01]],\n",
       " \n",
       "         [[-1.1984e-01, -2.7089e-01,  8.9898e-01,  ..., -5.5139e-01,\n",
       "            5.3209e-02, -2.6734e-01],\n",
       "          [ 1.1466e-02, -1.6306e-01, -1.8858e-01,  ..., -4.9520e-02,\n",
       "            3.6477e-01, -3.4026e-01],\n",
       "          [-2.3420e-01,  7.7354e-01,  7.0877e-01,  ...,  3.3911e-01,\n",
       "           -3.7330e-02,  3.3913e-01],\n",
       "          ...,\n",
       "          [-1.0661e+00, -6.6319e-01, -3.7443e-01,  ...,  1.5482e-01,\n",
       "            6.7418e-01, -4.7977e-01],\n",
       "          [ 4.0166e-01,  4.0303e-01, -1.7442e-01,  ..., -2.4375e-01,\n",
       "            1.9944e-01,  1.7666e-01],\n",
       "          [-8.1157e-02, -5.1417e-01, -1.1054e-01,  ...,  4.4366e-02,\n",
       "            3.8276e-01,  5.3009e-01]]], device='cuda:0',\n",
       "        grad_fn=<ViewBackward0>),\n",
       " torch.Size([8, 128, 30522]),\n",
       " tensor(10.4483, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = get_batch('train')\n",
    "logits, loss = gen(X, Y, tokenizer)\n",
    "logits, logits.size(), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99515706"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in gen.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(prompt='She was going to '):\n",
    "    prompt_ids = tokenizer(prompt, return_tensors='pt', add_special_tokens=False).input_ids\n",
    "    generated_ids = gen.generate(prompt_ids.to(device), max_new_tokens=20)\n",
    "    result = tokenizer.decode(generated_ids[0])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_deep(logits, targets):\n",
    "    # focus only on the last time step\n",
    "    logits = logits[:, -1, :] # becomes (B, C)\n",
    "    # apply softmax to obtain probabilities\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1).to(config.device) # (B, C)\n",
    "    index_next = torch.multinomial(probs, num_samples=1) # (B, C)\n",
    "\n",
    "    print(tokenizer.decode(index_next.squeeze(-1)))\n",
    "    print(tokenizer.decode(targets[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    if (not pretrained) or build_pretrained:\n",
    "        with open('text_generator.pkl', 'wb') as handler:\n",
    "            pickle.dump(gen, handler)\n",
    "    gen.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iter_ticks):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = gen(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "            test_deep(logits, Y)\n",
    "        out[split] = losses.mean()\n",
    "    gen.train()\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_pretrained:\n",
    "    with open('text_generator.pkl', 'wb') as handler:\n",
    "        pickle.dump(gen, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##leteuf plaza learned digit missile zeke appellate\n",
      "yelled her lethal steep who, of.\n",
      "0 tensor(10.4858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "'charged the.. the..\n",
      "brianending open logical well from taken,\n",
      "1 tensor(13.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tariff umar, reaper the [unused821] the the\n",
      ", he is shay a n her help\n",
      "2 tensor(15.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      ",,,,,,,,\n",
      "woman sea, unfortunately feel'squeezed past\n",
      "3 tensor(62.4383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "months arrived arrived arrived arrived arrived arrived months\n",
      ". class that beyond'screaming be layer\n",
      "4 tensor(188.3927, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if (not pretrained) or build_pretrained:\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(gen.parameters(), lr=learning_rate, weight_decay=0.01, amsgrad=True)\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        try:\n",
    "            \n",
    "            if (iter != 0) and (iter % eval_iters == 0):\n",
    "                losses = estimate_loss()\n",
    "                train_loss = losses['train']\n",
    "                val_loss = losses['val']\n",
    "                print(f'Loss at step = {iter} for train data is {train_loss:.4f} for val it is {val_loss:.4f}')\n",
    "\n",
    "            # sample a batch of data\n",
    "            xb, yb = get_batch('train')\n",
    "\n",
    "            # evaluate the loss\n",
    "            logits, loss = gen.forward(xb, yb, tokenizer)\n",
    "\n",
    "            if not torch.isnan(loss).any():\n",
    "                test_deep(logits, yb)\n",
    "                print(iter, loss)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                # torch.torch.nn.utils.clip_grad_norm_(gen.parameters(), max_norm=15.0)\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                print('NaN loss')\n",
    "                print(iter, loss)\n",
    "                input()\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('Summer season is upon us and you are all set to head to the beach or to an outdoor event. Outfit. Check, Sunglasses. Check. Hat. Check. Sunscreen? Well, check the ingredients before applying it. While sunscreen is essential for protecting your skin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('An apple is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('This was the greatest outcome for me because')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in gen.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'They wanted to fight and '\n",
    "test(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'He was walking on the middle of road when a car started coming at high speed behind him '\n",
    "test(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not pretrained) or build_pretrained:\n",
    "    with open('text_generator.pkl', 'wb') as handler:\n",
    "        pickle.dump(gen, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_generator.pkl', 'rb') as handler:\n",
    "    gen = pickle.load(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not pretrained) or build_pretrained:\n",
    "    # create a PyTorch optimizer\n",
    "    # optimizer = torch.optim.AdamW(gen.parameters(), lr=learning_rate, weight_decay=0.01, amsgrad=True)\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        try:\n",
    "            \n",
    "            if (iter != 0) and (iter % eval_iters == 0):\n",
    "                losses = estimate_loss()\n",
    "                train_loss = losses['train']\n",
    "                val_loss = losses['val']\n",
    "                print(f'Loss at step = {iter} for train data is {train_loss:.4f} for val it is {val_loss:.4f}')\n",
    "\n",
    "            # sample a batch of data\n",
    "            xb, yb = get_batch('train')\n",
    "\n",
    "            # evaluate the loss\n",
    "            logits, loss = gen.forward(xb, yb, tokenizer)\n",
    "            if not torch.isnan(loss).any():\n",
    "                test_deep(logits, yb)\n",
    "                print(iter, loss)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                # torch.torch.nn.utils.clip_grad_norm_(gen.parameters(), max_norm=15.0)\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                print('NaN loss')\n",
    "                print(iter, loss)\n",
    "                input()\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
